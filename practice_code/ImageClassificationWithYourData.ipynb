{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageClassificationWithYourData.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6JApzL6g_jQ"
      },
      "source": [
        "**Image classification with your own data**\n",
        "---\n",
        "\n",
        "Download the directories in this link https://drive.google.com/drive/folders/1Cfos2BCUdCriC_9ygHFUvA6SKr0YPZtJ?usp=sharing\n",
        "\n",
        "Before running code, make sure the training images are in the class directories for train, valid and test.\n",
        "\n",
        "1) Train directory is './drive/My Drive/public/train'\n",
        "\n",
        "2) Valid directory is './drive/My Drive/public/valid'\n",
        "\n",
        "3) Test directory is './drive/My Drive/public/test'\n",
        "\n",
        "For example, with 'HDH' and 'OH' classes \n",
        "* ./drive/My Drive/public/train/HDH/*.jpg\n",
        "* ./drive/My Drive/public/train/OH/*.jpg\n",
        "* ./drive/My Drive/public/valid/HDH/*.jpg\n",
        "* ./drive/My Drive/public/valid/OH/*.jpg\n",
        "* ./drive/My Drive/public/test/HDH/*.jpg\n",
        "* ./drive/My Drive/public/test/OH/*.jpg\n",
        "\n",
        "Initial tutorial code was provided by hchoi@handong.edu, Nov. 30, 2019. Code is updated in Jun. 23. 2020 for Gcamp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUQQHb4HKf8_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da2d91c8-9db2-4927-ea78-a35cd730e0b7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM4cBDItKoxt"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.autograd import Variable\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQt5CUzzh_z0"
      },
      "source": [
        "Define model architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4W51MsxM96w"
      },
      "source": [
        "class MyCNN(nn.Module):\n",
        "    def __init__(self, output_dim=10):\n",
        "        super(MyCNN,self).__init__()\n",
        "\n",
        "        self.output_dim=output_dim\n",
        "\n",
        "        self.cnn_layers = nn.Sequential(\n",
        "            nn.Conv2d(3,32,3,padding=1), # try with different kernels\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32,32,3,padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(4,4), # 32 x (25x25)\n",
        "            \n",
        "            nn.Conv2d(32,16,3,padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16,16,3,padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(5,5) # 16 x (5x5) \n",
        "        )\n",
        "        conv_size = self.get_conv_size(3, input_size)\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Linear(conv_size,100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100,output_dim)\n",
        "        )       \n",
        "\n",
        "    def get_conv_size(self, channel, shape):\n",
        "        o = self.cnn_layers(torch.zeros(1, channel, *shape))\n",
        "        return int(np.prod(o.size()))\n",
        "        \n",
        "    def forward(self,x):\n",
        "        batch_size, c, h, w = x.data.size()\n",
        "        out = self.cnn_layers(x)\n",
        "        out = out.view(batch_size, -1)\n",
        "        out = self.fc_layer(out)\n",
        "        return out\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rC_j9RVnnEyN"
      },
      "source": [
        "Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8B_xsZGJl9v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8adf7d0d-99a4-4dbd-e456-35379839f180"
      },
      "source": [
        "resize=(120, 120)\n",
        "input_size=(100, 100)\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize(resize),\n",
        "        #transforms.RandomCrop(input_size), # data augmentation\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.3, 0.3, 0.3])\n",
        "    ]),\n",
        "    'valid': transforms.Compose([\n",
        "        transforms.Resize(resize),\n",
        "        transforms.CenterCrop(input_size),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.3, 0.3, 0.3])\n",
        "    ]),\n",
        "}\n",
        "test_transform = data_transforms['valid']\n",
        "\n",
        "batch_size = 64 # try different batch_size values\n",
        "data_dir = './drive/My Drive/public/'\n",
        "train_dir = 'train'\n",
        "valid_dir = 'valid'\n",
        "\n",
        "train_set = datasets.ImageFolder(data_dir+train_dir, data_transforms['train'])\n",
        "valid_set = datasets.ImageFolder(data_dir+valid_dir, data_transforms['valid'])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
        "                                              shuffle=True, num_workers=4)\n",
        "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=batch_size,\n",
        "                                              shuffle=True, num_workers=4)\n",
        "\n",
        "train_size = len(train_set)\n",
        "valid_size = len(valid_set)\n",
        "\n",
        "class_names = train_set.classes\n",
        "print(class_names)\n",
        "\n",
        "print(f'Train image samples: {train_size}')\n",
        "print(f'Validation image samples: {valid_size}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ANH', 'HDH', 'Hyoam', 'NTH', 'OH']\n",
            "Train image samples: 4054\n",
            "Validation image samples: 241\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFlBgBxhQRKj"
      },
      "source": [
        "Define training parameters and model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KO9dBirzQPwO",
        "outputId": "c0102078-b982-4095-b6aa-6db87a438c47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "num_epoch = 10 # try with different epochs and find the best epoch\n",
        "patience=5\n",
        "output_dim=5\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = MyCNN(output_dim=output_dim).to(device)\n",
        "param_list = list(model.children())\n",
        "print(param_list)\n",
        "\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "#optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Sequential(\n",
            "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): ReLU()\n",
            "  (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (3): ReLU()\n",
            "  (4): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
            "  (5): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (6): ReLU()\n",
            "  (7): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (8): ReLU()\n",
            "  (9): MaxPool2d(kernel_size=5, stride=5, padding=0, dilation=1, ceil_mode=False)\n",
            "), Sequential(\n",
            "  (0): Linear(in_features=400, out_features=100, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=100, out_features=5, bias=True)\n",
            ")]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBM8GgSNiZ6m"
      },
      "source": [
        "Training and validating loop\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eDi5Aeba8Ha",
        "outputId": "538bb708-62bb-445e-c16f-5868b2f5e2f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "total_loss = 0.0\n",
        "n_steps = 0\n",
        "bad_counter = 0\n",
        "best_vacc = None\n",
        "best_epoch = None\n",
        "\n",
        "result_dir = 'drive/My Drive/public/results/'\n",
        "if not os.path.exists(result_dir):\n",
        "    os.mkdir(result_dir)\n",
        "\n",
        "for i in range(num_epoch):\n",
        "    model.train()\n",
        "    for j, [image,label] in enumerate(train_loader):\n",
        "        x = image.to(device)\n",
        "        y_= label.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x)\n",
        "        loss = loss_func(output,y_)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        n_steps += 1\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print('[TRAIN LOSS] ', 'Epochs {:d} Loss {:.4f}'.format(i+1, total_loss / n_steps))\n",
        "    total_loss, n_steps = 0.0, 0\n",
        "\n",
        "    model.eval()\n",
        "    hits = 0\n",
        "    for k,[image,label] in enumerate(valid_loader):\n",
        "        x = image.to(device)\n",
        "        y_= label.to(device)\n",
        "\n",
        "        output = model(x)\n",
        "        y_est = output.argmax(1)\n",
        "        hits = hits + torch.sum(y_est == y_).item()\n",
        "\n",
        "    vacc = float(int(hits)/(valid_size+0.0))\n",
        "    print('[VALID ACC] ', 'Epochs', i, 'Hits', int(hits), 'Accuracy {:.4f}'.format(vacc))\n",
        "\n",
        "    if best_vacc is None or best_vacc < vacc:\n",
        "        best_vacc = vacc\n",
        "        bad_counter = 0\n",
        "        best_epoch = i+1\n",
        "        torch.save(model, result_dir + 'own_data.pth.best')\n",
        "    else:\n",
        "        bad_counter +=1\n",
        "    if bad_counter >= patience:\n",
        "        break\n",
        "\n",
        "print('best epoch: ', best_epoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[TRAIN LOSS]  Epochs 1 Loss 0.8063\n",
            "[VALID ACC]  Epochs 0 Hits 220 Accuracy 0.9129\n",
            "[TRAIN LOSS]  Epochs 2 Loss 0.2032\n",
            "[VALID ACC]  Epochs 1 Hits 226 Accuracy 0.9378\n",
            "[TRAIN LOSS]  Epochs 3 Loss 0.1314\n",
            "[VALID ACC]  Epochs 2 Hits 230 Accuracy 0.9544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klAJEc3Pg9-d"
      },
      "source": [
        "Test the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rCqCX6NjQZ1"
      },
      "source": [
        "test_batch_size = 10\n",
        "model_name = 'own_data.pth.best'\n",
        "\n",
        "model = torch.load(result_dir + model_name)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "test_dir = 'drive/My Drive/public/valid2'\n",
        "test_set = datasets.ImageFolder(test_dir, test_transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=test_batch_size,\n",
        "                                          shuffle=False, num_workers=4)\n",
        "\n",
        "hits = 0\n",
        "for k,[image,label] in enumerate(test_loader):\n",
        "    x = image.to(device)\n",
        "    y_= label.to(device)\n",
        "\n",
        "    output = model(x)\n",
        "    y_est = output.argmax(1)\n",
        "    print('Target', label.numpy(), 'Prediction', y_est.cpu().numpy())\n",
        "    hits = hits + torch.sum(y_est == y_).item()\n",
        "\n",
        "print('[TEST] ', 'hits', int(hits),'accuracy {:.4f}'.format(float(hits/(len(test_set)+0.0))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nN4IZGVQgzP0"
      },
      "source": [
        "classify one image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIROsL_pY__p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ddbf06a4-b5f7-4e80-ccaf-d71d691320c5"
      },
      "source": [
        "from skimage import io\n",
        "\n",
        "img_name = './drive/My Drive/public/test/test1.jpg'\n",
        "test_img = io.imread(img_name)\n",
        "test_img = transforms.ToPILImage()(test_img)\n",
        "test_img = test_transform(test_img)\n",
        "test_data = test_img.unsqueeze(0).to(device)\n",
        "\n",
        "output=model(test_data)\n",
        "\n",
        "class_id = output.argmax(dim=1).cpu().numpy()[0]\n",
        "print(img_name.split('/')[-1], '==>', class_id, class_names[class_id])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test1.jpg ==> 0 ANH\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hk9Nvlpxg6ew"
      },
      "source": [
        "classify all images in a directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsJeM_g0ZBNk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 994
        },
        "outputId": "cfde82c5-c369-48bc-f934-d56ca9d14ce5"
      },
      "source": [
        "from skimage import io\n",
        "import glob\n",
        "\n",
        "img_dir = 'drive/My Drive/public/test/'\n",
        "file_list = glob.glob(img_dir + '*.*')\n",
        "for img_name in file_list:\n",
        "  test_img = io.imread(img_name)\n",
        "  test_img = transforms.ToPILImage()(test_img)\n",
        "  test_img = test_transform(test_img)\n",
        "  test_data = test_img.unsqueeze(0).to(device)\n",
        "\n",
        "  output=model(test_data)\n",
        "\n",
        "  class_id = output.argmax(dim=1).cpu().numpy()[0]\n",
        "  print(img_name.split('/')[-1], '==>', class_id, class_names[class_id])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "please print?\n",
            "53\n",
            "D11_NTH15.jpeg ==> 3 NTH\n",
            "D08_OH29.jpg ==> 4 OH\n",
            "D15_OH31.jpg ==> 3 NTH\n",
            "D18_Hyoam38.JPG ==> 2 Hyoam\n",
            "D05_NTH03.jpg ==> 3 NTH\n",
            "D17_NTH08.jpg ==> 3 NTH\n",
            "D03_OH13.jpg ==> 4 OH\n",
            "D05_NTH31.jpg ==> 3 NTH\n",
            "D17_Hyoam39.jpeg ==> 2 Hyoam\n",
            "D09_NTH30.jpg ==> 3 NTH\n",
            "D12_NTH15.jpg ==> 3 NTH\n",
            "D01_Hyoam41.jpg ==> 2 Hyoam\n",
            "D04_OH18.jpeg ==> 4 OH\n",
            "D06_OH41.jpg ==> 3 NTH\n",
            "D13_NTH30.jpg ==> 3 NTH\n",
            "D05_NTH45.jpg ==> 3 NTH\n",
            "D12_OH21.jpg ==> 4 OH\n",
            "D06_OH29.jpg ==> 4 OH\n",
            "D11_NTH30.jpeg ==> 3 NTH\n",
            "D18_NTH30.jpg ==> 3 NTH\n",
            "D14_OH12.jpg ==> 4 OH\n",
            "D11_NTH01.jpeg ==> 3 NTH\n",
            "D15_OH43.jpg ==> 0 ANH\n",
            "D16_OH34.jpg ==> 4 OH\n",
            "D01_OH22.jpg ==> 4 OH\n",
            "D18_Hyoam40.JPG ==> 2 Hyoam\n",
            "D07_HDH07.jpg ==> 1 HDH\n",
            "D18_ANH48.jpg ==> 3 NTH\n",
            "D11_Hyoam05.JPG ==> 2 Hyoam\n",
            "D06_ANH32.jpg ==> 0 ANH\n",
            "D07_ANH22.jpg ==> 0 ANH\n",
            "D15_HDH04.JPG ==> 4 OH\n",
            "D12_HDH10.jpg ==> 1 HDH\n",
            "D12_AHN36.jpg ==> 0 ANH\n",
            "D14_Hyoam12.jpg ==> 2 Hyoam\n",
            "test1.jpg ==> 0 ANH\n",
            "D08_Hyoam09.jpg ==> 2 Hyoam\n",
            "D09_Hyoam09.JPG ==> 2 Hyoam\n",
            "D07_HDH45.jpg ==> 4 OH\n",
            "D13_ANH47.jpg ==> 3 NTH\n",
            "D08_ANH23.jpg ==> 0 ANH\n",
            "D07_HDH17.jpg ==> 0 ANH\n",
            "D10_ANH46.jpg ==> 0 ANH\n",
            "D07_HDH49.jpg ==> 4 OH\n",
            "D02_HDH50.jpg ==> 1 HDH\n",
            "D15_Hyoam47.jpg ==> 2 Hyoam\n",
            "D06_HDH08.jpg ==> 1 HDH\n",
            "D13_ANH45.jpg ==> 0 ANH\n",
            "D10_ANH09.jpg ==> 0 ANH\n",
            "D09_HDH31.JPG ==> 2 Hyoam\n",
            "D13_ANH01.jpg ==> 0 ANH\n",
            "D07_HDH30.jpg ==> 3 NTH\n",
            "D09_Hyoam31.JPG ==> 2 Hyoam\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6kZDqJpi74n"
      },
      "source": [
        "The end! (hchoi@handong.edu)\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ]
}