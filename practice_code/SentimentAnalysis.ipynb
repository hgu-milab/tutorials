{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SentimentAnalysis.ipynb","provenance":[{"file_id":"11wcpRt7nvIJ4GxLCIXwiFqEqmD3_TSZ4","timestamp":1657627679291}],"collapsed_sections":[],"authorship_tag":"ABX9TyMy1t+gEPDlTDJu2RWu+4hK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Most of sources are from https://github.com/bentrevett/pytorch-sentiment-analysis"],"metadata":{"id":"CQW99v_8Zfrx"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h-cTBWnMRqE4","executionInfo":{"status":"ok","timestamp":1657627168116,"user_tz":-540,"elapsed":25200,"user":{"displayName":"허동녕","userId":"09702490062530136390"}},"outputId":"3ebb94e2-972d-40d9-c813-7f207796a796"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html\n","pip install torchtext==0.9.0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KKctd6CqPq3a","executionInfo":{"status":"ok","timestamp":1657626831412,"user_tz":-540,"elapsed":224373,"user":{"displayName":"허동녕","userId":"09702490062530136390"}},"outputId":"198b3888-635d-4c45-e7fe-3032196c420d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.8.0+cu111\n","  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (1982.2 MB)\n","\u001b[K     |█████████████▌                  | 834.1 MB 1.4 MB/s eta 0:13:40tcmalloc: large alloc 1147494400 bytes == 0x3a930000 @  0x7f99ad1f2615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |█████████████████               | 1055.7 MB 1.4 MB/s eta 0:11:06tcmalloc: large alloc 1434370048 bytes == 0x7ef86000 @  0x7f99ad1f2615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |█████████████████████▋          | 1336.2 MB 1.4 MB/s eta 0:07:47tcmalloc: large alloc 1792966656 bytes == 0x3db8000 @  0x7f99ad1f2615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |███████████████████████████▎    | 1691.1 MB 1.2 MB/s eta 0:03:57tcmalloc: large alloc 2241208320 bytes == 0x6eba0000 @  0x7f99ad1f2615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x598e3b 0x511f68 0x598e3b 0x511f68 0x598e3b 0x511f68 0x4bc98a 0x532e76 0x594b72 0x515600 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x5118f8 0x593dd7\n","\u001b[K     |████████████████████████████████| 1982.2 MB 1.4 MB/s eta 0:00:01tcmalloc: large alloc 1982251008 bytes == 0xf4502000 @  0x7f99ad1f11e7 0x4a3940 0x4a39cc 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9\n","tcmalloc: large alloc 2477817856 bytes == 0x16a76e000 @  0x7f99ad1f2615 0x592b76 0x4df71e 0x59afff 0x515655 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x549576 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576\n","\u001b[K     |████████████████████████████████| 1982.2 MB 4.9 kB/s \n","\u001b[?25hCollecting torchvision==0.9.0+cu111\n","  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (17.6 MB)\n","\u001b[K     |████████████████████████████████| 17.6 MB 1.3 MB/s \n","\u001b[?25hCollecting torchaudio==0.8.0\n","  Downloading torchaudio-0.8.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n","\u001b[K     |████████████████████████████████| 1.9 MB 5.5 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu111) (4.1.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu111) (1.21.6)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.0+cu111) (7.1.2)\n","Installing collected packages: torch, torchvision, torchaudio\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.11.0+cu113\n","    Uninstalling torch-1.11.0+cu113:\n","      Successfully uninstalled torch-1.11.0+cu113\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.12.0+cu113\n","    Uninstalling torchvision-0.12.0+cu113:\n","      Successfully uninstalled torchvision-0.12.0+cu113\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 0.11.0+cu113\n","    Uninstalling torchaudio-0.11.0+cu113:\n","      Successfully uninstalled torchaudio-0.11.0+cu113\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.8.0+cu111 which is incompatible.\u001b[0m\n","Successfully installed torch-1.8.0+cu111 torchaudio-0.8.0 torchvision-0.9.0+cu111\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","import os\n","from torchtext.legacy import data, datasets\n","import random\n","import json"],"metadata":{"id":"bAtKcQV-RDcn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tokenizing whole dataset once and save it!\n","TEXT = data.Field(tokenize='spacy')\n","LABEL = data.LabelField()\n","\n","print(\"Downloading and tokenizing\")\n","train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n","\n","print(\"Make dataset\")\n","train_examples = [vars(t) for t in train_data]\n","test_examples = [vars(t) for t in test_data]\n","\n","print(\"Storing\")\n","if not os.path.exists('./drive/My Drive/public/data/imdb'):\n","    os.mkdir('./drive/My Drive/public/data/imdb')\n","\n","with open('./drive/My Drive/public/data/imdb/sentiment_train.json', 'w+') as f:\n","    for example in train_examples:\n","        json.dump(example, f)\n","        f.write('\\n')\n","        \n","with open('./drive/My Drive/public/data/imdb/sentiment_test.json', 'w+') as f:\n","    for example in test_examples:\n","        json.dump(example, f)\n","        f.write('\\n')\n","\n","print(\"Done\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vvHBvjKuRASh","executionInfo":{"status":"ok","timestamp":1657627244201,"user_tz":-540,"elapsed":66159,"user":{"displayName":"허동녕","userId":"09702490062530136390"}},"outputId":"607b8f32-b90c-43ac-af1f-de1c4e99b904"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchtext/data/utils.py:123: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n","  warnings.warn(f'Spacy model \"{language}\" could not be loaded, trying \"{OLD_MODEL_SHORTCUTS[language]}\" instead')\n"]},{"output_type":"stream","name":"stdout","text":["Downloading and tokenizing\n","Make dataset\n","Storing\n","Done\n"]}]},{"cell_type":"code","source":["TEXT = data.Field()\n","LABEL = data.LabelField()\n","\n","fields = {'text': ('text', TEXT), 'label': ('label', LABEL)}\n","\n","train_data, test_data = data.TabularDataset.splits(\n","    path = './drive/My Drive/public/data/imdb',\n","    train = 'sentiment_train.json',\n","    test = 'sentiment_test.json',\n","    format = 'json',\n","    fields = fields\n",")\n","\n","print(\"Splitting for train and validation\")\n","train_data, valid_data = train_data.split(random_state = random.seed(1234))\n","\n","MAX_VOCAB_SIZE = 25_000\n","\n","print(\"Generating vocabulary sets\")\n","TEXT.build_vocab(train_data, \n","                 max_size = MAX_VOCAB_SIZE, \n","                 vectors = \"glove.6B.100d\", \n","                 unk_init = torch.Tensor.normal_)\n","LABEL.build_vocab(train_data)\n","\n","print(\"Done\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ztt73Y_SNyo","executionInfo":{"status":"ok","timestamp":1657627499498,"user_tz":-540,"elapsed":207481,"user":{"displayName":"허동녕","userId":"09702490062530136390"}},"outputId":"7ab541e2-f260-4631-d05f-bb8cf39cd763"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Splitting for train and validation\n","Generating vocabulary sets\n"]},{"output_type":"stream","name":"stderr","text":[".vector_cache/glove.6B.zip: 862MB [02:39, 5.40MB/s]                           \n","100%|█████████▉| 399999/400000 [00:16<00:00, 24807.62it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Done\n"]}]},{"cell_type":"code","source":["print(\"Number of training data : \", len(train_data))\n","print(\"Number of validation data : \", len(valid_data))\n","print(\"Number of test data : \", len(test_data))\n","\n","print(\"Number of unique tokens of data vocab. : \", len(TEXT.vocab))\n","print(\"Number of unique tokens of label vocab. : \", len(LABEL.vocab))\n","\n","print(\"One of the training example\")\n","print(vars(train_data.examples[0]))\n","\n","print(\"Vocabulary set\")\n","print(TEXT.vocab.itos[:10])\n","print(LABEL.vocab.stoi)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nzcKVaiZTI_-","executionInfo":{"status":"ok","timestamp":1657627522523,"user_tz":-540,"elapsed":300,"user":{"displayName":"허동녕","userId":"09702490062530136390"}},"outputId":"63b3a121-98c4-409b-cc0a-6297dadc02a2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of training data :  17500\n","Number of validation data :  7500\n","Number of test data :  25000\n","Number of unique tokens of data vocab. :  25002\n","Number of unique tokens of label vocab. :  2\n","One of the training example\n","{'text': ['We', 'expected', 'something', 'great', 'when', 'we', 'went', 'to', 'see', 'this', 'bomb', '.', 'It', 'is', 'basically', 'a', 'Broadway', 'play', 'put', 'on', 'film', '.', 'The', 'music', 'is', 'plain', 'terrible', '.', 'There', 'is', \"n't\", 'one', 'memorable', 'song', 'in', 'the', 'movie', '--', 'heard', 'any', 'hits', 'from', 'this', 'movie', '?', 'You', 'wo', \"n't\", 'because', 'there', 'are', \"n't\", 'any', '.', 'Some', 'of', 'the', 'musical', 'numbers', 'go', 'on', 'so', 'long', 'that', 'I', 'got', 'up', 'to', 'go', 'to', 'the', 'restroom', 'and', 'get', 'some', 'pop', 'corn', 'and', 'it', 'was', 'still', 'going', 'when', 'I', 'got', 'back', '!', 'If', 'they', 'were', 'good', 'songs', 'well', '--', 'but', 'they', 'suck', '.', 'The', 'pace', 'is', 'slow', ',', 'terrible', 'character', 'development', '.', 'The', 'lead', 'was', 'praised', 'for', 'her', 'singing', 'but', 'sounded', 'like', 'she', 'screamed', 'every', 'song', '--', 'it', 'was', 'almost', 'impossible', 'to', 'stand', '.', 'This', 'movie', 'has', 'NOTHING', 'to', 'offer', 'anyone', 'but', 'die', '-', 'hard', 'Broadway', 'enthusiasts', '.', 'This', 'is', 'without', 'a', 'doubt', 'the', 'most', 'over', 'rated', 'movie', 'I', \"'ve\", 'seen', 'in', 'my', 'entire', 'life', '.', 'A', 'complete', 'waist', 'of', 'time', 'and', 'money', '.', 'There', 'is', 'nothing', 'memorable', 'about', 'this', 'movie', 'except', 'Danny', 'Glover', '--', 'who', 'was', \"n't\", 'on', 'screen', 'enough', 'and', 'whose', 'character', 'was', \"n't\", 'developed', 'enough', '.', 'Rent', 'the', 'video', 'and', 'you', \"'ll\", 'agree', '--', 'this', 'movie', 'was', 'an', 'expensive', ',', 'over', 'produced', ',', 'polished', 'dog', 'do', '.'], 'label': 'neg'}\n","Vocabulary set\n","['<unk>', '<pad>', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']\n","defaultdict(None, {'neg': 0, 'pos': 1})\n"]}]},{"cell_type":"code","source":["BATCH_SIZE = 64\n","\n","INPUT_DIM = len(TEXT.vocab)\n","EMBEDDING_DIM = 100\n","HIDDEN_DIM = 256\n","OUTPUT_DIM = 2\n","DROPOUT = 0.5\n","\n","LR = 0.001\n","OPTIMIZER = 'Adam'\n","MAX_EPOCH = 5\n","\n","RNN_TYPE = 'rnn'\n","PRETRAIN_EMBEDDING = 0\n","BIDIRECTIONAL = False\n","N_LAYERS = 1"],"metadata":{"id":"Chf3lCsiTNtD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class RNN(nn.Module):\n","    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim,\\\n","                dropout, rnn_type, bidirectional, n_layers):\n","        super().__init__()\n","        self.rnn_type = rnn_type\n","        self.bidir = bidirectional\n","        if self.bidir == True:\n","            bi_coeff = 2\n","        else:\n","            bi_coeff = 1\n","\n","        self.embedding = nn.Embedding(input_dim, embedding_dim)\n","        if rnn_type == 'rnn':\n","            self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers=n_layers, \\\n","                              bidirectional=bidirectional)\n","        elif rnn_type == 'lstm':\n","            self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers,\\\n","                               bidirectional=bidirectional)\n","        \n","        self.fc = nn.Linear(bi_coeff*hidden_dim, output_dim)\n","        self.dropout = nn.Dropout(dropout)\n","\n","        self.criterion = nn.CrossEntropyLoss()\n","        self.softmax = nn.Softmax(dim=1)\n","        \n","    def forward(self, text, label):\n","        # text (Timeseq, Batch)\n","        Tx, Bn = text.size()\n","        embedded = self.dropout(self.embedding(text))\n","        # embedded (Timeseq, Batch, emb_dim)\n","\n","        if self.rnn_type == 'rnn':\n","            output, hidden = self.rnn(embedded)\n","        elif self.rnn_type == 'lstm':\n","            output, (hidden, cell) = self.rnn(embedded)\n","        \n","        if self.bidir == True:\n","            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n","        else:\n","            hidden = self.dropout(hidden[-1,:,:])\n","        # hidden (Batch, hidden_dim*direction)\n","        \n","        logit = self.fc(hidden)\n","        # logit (Batch, output_dim)\n","\n","        if label is not None:\n","            loss = self.criterion(logit, label)\n","        else:\n","            loss = 0\n","        probs = self.softmax(logit)\n","        # probs (Batch, output_dim)\n","\n","        return loss, probs"],"metadata":{"id":"z5f7176TTS1p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(model, device, train_loader, optimizer, epoch):\n","    model.train()\n","    \n","    correct = 0\n","    den = 0\n","    train_loss = 0\n","    for batch_idx, (batch) in enumerate(train_loader):\n","        den += 1\n","        text = batch.text.to(device)\n","        label = batch.label.to(device)\n","              \n","        optimizer.zero_grad()\n","        loss, probs = model(text, label)\n","        loss.backward()\n","        optimizer.step()\n","\n","        pred = torch.argmax(probs, dim=1)\n","        correct += (pred == label).float().sum().item()\n","        train_loss += loss.item()\n","  \n","        Tx, Bn = text.size()\n","        \n","    acc = correct / len(train_loader.dataset)\n","    train_loss /= den\n","    print('Epoch {} Train: Loss: {:.6f} \\tAcc.: {:.6f}'.format(\n","                epoch, train_loss, acc))   \n","    \n","            \n","def test(model, device, test_loader, epoch):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    den = 0\n","    with torch.no_grad():\n","        for batch in test_loader:\n","            den += 1\n","            text = batch.text.to(device)\n","            label = batch.label.to(device)\n","            \n","            loss, probs = model(text, label)\n","            pred = torch.argmax(probs, dim=1)\n","\n","            test_loss += loss.item()\n","            \n","            correct += (pred == label).float().sum()\n","\n","    test_loss /= den\n","    acc = correct / len(test_loader.dataset)\n","\n","    print('Epoch {} Test : Loss: {:.6f} \\tAcc.: {:.6f}\\n'.format(\n","        epoch, test_loss, acc))\n","    return acc"],"metadata":{"id":"PSzIQCmETUhG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["### Training\n","# Check the device\n","cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if cuda else \"cpu\")\n","\n","# Datasets\n","train_loader = data.BucketIterator(train_data, batch_size = BATCH_SIZE)\n","valid_loader = data.BucketIterator(valid_data, batch_size = BATCH_SIZE)\n","test_loader = data.BucketIterator(test_data, batch_size = BATCH_SIZE)\n","\n","# build my model\n","model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, DROPOUT, RNN_TYPE, BIDIRECTIONAL, N_LAYERS)\n","if PRETRAIN_EMBEDDING == 1:\n","    pretrained_embeddings = TEXT.vocab.vectors\n","    model.embedding.weight.data.copy_(pretrained_embeddings)\n","model.to(device)\n","\n","# build the optimizer\n","if OPTIMIZER == 'RMSprop':\n","    opt = optim.RMSprop(model.parameters(), lr=LR)\n","elif OPTIMIZER == 'Adam':\n","    opt = optim.Adam(model.parameters(), lr=LR)\n","elif OPTIMIZER == 'Adadelta':\n","    opt = optim.Adadelta(model.parameters(), lr=LR)\n","else:\n","    opt = optim.SGD(model.parameters(), lr=LR)\n","\n","# Training..\n","print(\"Training Start!\")\n","best_acc = 0\n","for epoch in range(MAX_EPOCH):\n","    train(model, device, train_loader, opt, epoch)\n","    valid_acc = test(model, device, valid_loader, epoch)\n","\n","    if best_acc < valid_acc:\n","        print(\"We found the best model!\\n\")\n","        best_acc = valid_acc\n","        save_dir = 'drive/My Drive/public/results/sentiment_analysis_model_best.pth'\n","        if os.path.exists(save_dir):\n","            os.remove(save_dir)\n","        torch.save(model, save_dir)\n","    \n","print(\"Training is done!!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":420},"id":"8mvWro6sTYsB","executionInfo":{"status":"error","timestamp":1657627645793,"user_tz":-540,"elapsed":45744,"user":{"displayName":"허동녕","userId":"09702490062530136390"}},"outputId":"38e6116e-2605-4ee1-8d4d-bb8b99bb89dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training Start!\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-b0fe5973ead3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mbest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_EPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-14-ad183cc8f688>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["import spacy\n","nlp = spacy.load('en')\n","\n","def predict_sentiment(model, sentence):\n","    model.eval()\n","    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n","    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n","    tensor = torch.LongTensor(indexed).to(device)\n","    tensor = tensor.unsqueeze(1)\n","    _, probs = model(tensor, None)\n","\n","    return probs"],"metadata":{"id":"6-sOemSXTrSI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["probs = predict_sentiment(model, \"This film is Wonderful\")\n","print(probs) #[neg, pos]"],"metadata":{"id":"pYbMI7WaTtW3"},"execution_count":null,"outputs":[]}]}