{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "chl_imagenet_and_transfer_learning_colab_example.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCagN69eQlGa"
      },
      "source": [
        "ImageNet example\n",
        "\n",
        "* copy the whole directory 'imagenet_install' available at https://drive.google.com/drive/folders/1DI0LW0cSeeGM_NFVbdMOtp3JDQk8JCUu?usp=sharing\n",
        " \n",
        "> * upload it to drive/My Drive/public/. (make sure you have a directory 'drive/My Drive/public/imagenet_install')\n",
        "\n",
        "* Move the public/images folder to 'drive/My Drive/public/data/images/.'\n",
        "\n",
        "**Outline**\n",
        "* Image Classification with Pre-trained Model\n",
        "\n",
        " * Mount Google Drive\n",
        "\n",
        " * Download and load pre-trained model\n",
        "\n",
        " * Image classification with pre-trained model\n",
        "\n",
        " In pre-trained model experiment, data and results will be stored in,\n",
        " 1. Imagenet Data: './drive/My Drive/public/data/images'\n",
        " 2. Trained Model: './drive/My Drive/public/results/'\n",
        "\n",
        "\\\\\n",
        "\n",
        "* Transfer Learning with pre-trained Model\n",
        "\n",
        " * Load pre-trained model\n",
        "\n",
        " * Configure optimizer: only training the last layer\n",
        "\n",
        " * Load dataset\n",
        "\n",
        " * Training\n",
        "\n",
        " * Testing\n",
        "\n",
        " * Image \n",
        "\n",
        " In fine-tuning experiment, toy dataset and results are stored in,\n",
        " 1. './drive/My Drive/public/data/images'\n",
        " 2. './drive/My Drive/public/results/'\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "yPW-DzjZj0L9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xL-qRuqmQqNd",
        "outputId": "cf759d49-1f92-4739-ee73-c88abe111757"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9JCgyHlk1sg"
      },
      "source": [
        "configuration to download a pretrained model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5snmGBbQeOt",
        "outputId": "8b389d3d-251e-43e9-a47f-0316109bc835"
      },
      "source": [
        "!pip install pretrainedmodels\n",
        "!python ./drive/'My Drive'/public/imagenet_install/setup.py install"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pretrainedmodels in /usr/local/lib/python3.7/dist-packages (0.7.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels) (4.64.0)\n",
            "Requirement already satisfied: munch in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels) (2.5.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels) (0.12.0+cu113)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels) (1.11.0+cu113)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from munch->pretrainedmodels) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pretrainedmodels) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->pretrainedmodels) (2.23.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->pretrainedmodels) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->pretrainedmodels) (1.21.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->pretrainedmodels) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->pretrainedmodels) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->pretrainedmodels) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->pretrainedmodels) (1.24.3)\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating pretrainedmodels.egg-info\n",
            "writing pretrainedmodels.egg-info/PKG-INFO\n",
            "writing dependency_links to pretrainedmodels.egg-info/dependency_links.txt\n",
            "writing requirements to pretrainedmodels.egg-info/requires.txt\n",
            "writing top-level names to pretrainedmodels.egg-info/top_level.txt\n",
            "writing manifest file 'pretrainedmodels.egg-info/SOURCES.txt'\n",
            "reading manifest file 'pretrainedmodels.egg-info/SOURCES.txt'\n",
            "writing manifest file 'pretrainedmodels.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "warning: install_lib: 'build/lib' does not exist -- no Python modules to install\n",
            "\n",
            "creating build\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pretrainedmodels.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pretrainedmodels.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pretrainedmodels.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pretrainedmodels.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying pretrainedmodels.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/pretrainedmodels-0.7.4-py3.7.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing pretrainedmodels-0.7.4-py3.7.egg\n",
            "Copying pretrainedmodels-0.7.4-py3.7.egg to /usr/local/lib/python3.7/dist-packages\n",
            "Adding pretrainedmodels 0.7.4 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/pretrainedmodels-0.7.4-py3.7.egg\n",
            "Processing dependencies for pretrainedmodels==0.7.4\n",
            "Searching for tqdm==4.64.0\n",
            "Best match: tqdm 4.64.0\n",
            "Adding tqdm 4.64.0 to easy-install.pth file\n",
            "Installing tqdm script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for munch==2.5.0\n",
            "Best match: munch 2.5.0\n",
            "Adding munch 2.5.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for torchvision==0.12.0+cu113\n",
            "Best match: torchvision 0.12.0+cu113\n",
            "Adding torchvision 0.12.0+cu113 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for torch==1.11.0+cu113\n",
            "Best match: torch 1.11.0+cu113\n",
            "Adding torch 1.11.0+cu113 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "Installing torchrun script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for six==1.15.0\n",
            "Best match: six 1.15.0\n",
            "Adding six 1.15.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for typing-extensions==4.1.1\n",
            "Best match: typing-extensions 4.1.1\n",
            "Adding typing-extensions 4.1.1 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for Pillow==7.1.2\n",
            "Best match: Pillow 7.1.2\n",
            "Adding Pillow 7.1.2 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for numpy==1.21.6\n",
            "Best match: numpy 1.21.6\n",
            "Adding numpy 1.21.6 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.7 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for requests==2.23.0\n",
            "Best match: requests 2.23.0\n",
            "Adding requests 2.23.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for certifi==2022.6.15\n",
            "Best match: certifi 2022.6.15\n",
            "Adding certifi 2022.6.15 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for chardet==3.0.4\n",
            "Best match: chardet 3.0.4\n",
            "Adding chardet 3.0.4 to easy-install.pth file\n",
            "Installing chardetect script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for idna==2.10\n",
            "Best match: idna 2.10\n",
            "Adding idna 2.10 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for urllib3==1.24.3\n",
            "Best match: urllib3 1.24.3\n",
            "Adding urllib3 1.24.3 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Finished processing dependencies for pretrainedmodels==0.7.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ny4I1gflBdc"
      },
      "source": [
        "download a pretrained model and prepare a transformation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-v9F3I_Wy-i"
      },
      "source": [
        "import pretrainedmodels\n",
        "import pretrainedmodels.utils as utils\n",
        "import torch\n",
        "import os\n",
        "import warnings\n",
        "import ssl\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FoG0lH8Q_ni"
      },
      "source": [
        "# load the model if you have downloaded and saved a model. \n",
        "model_name = 'nasnetalarge' # could be fbresnet152 or inceptionresnetv2\n",
        "model_file = 'drive/My Drive/public/results/imagenet_nasnetalarge.pth'\n",
        "if os.path.exists(model_file):\n",
        "  model = torch.load(model_file)\n",
        "else:\n",
        "  model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n",
        "  if not os.path.exists('drive/My Drive/public/results'):\n",
        "      os.mkdir('drive/My Drive/public/results')    \n",
        "  torch.save(model, model_file)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "import pretrainedmodels.utils as utils\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "load_img = utils.LoadImage()\n",
        "transform_img = utils.TransformImage(model) #input_size = (331, 331) "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvwJb2iKlOHn"
      },
      "source": [
        "imagenet class names "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-11drDe28vI"
      },
      "source": [
        "import csv\n",
        "name_file = 'drive/My Drive/public/imagenet_install/class_names.csv'\n",
        "\n",
        "imagenet_class  = {} \n",
        "file_in = csv.reader(open(name_file))\n",
        "for row in file_in:\n",
        "  imagenet_class[int(row[0])] = row[1]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhYw2wDsAzQ0",
        "outputId": "736db4b7-b84b-495a-9b79-1bc17c0f8511"
      },
      "source": [
        "print(imagenet_class)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'tench, Tinca tinca', 1: 'goldfish, Carassius auratus', 2: 'great white shark, white shark, man-eater, man-eating shark, Carcharodon carcharias', 3: 'tiger shark, Galeocerdo cuvieri', 4: 'hammerhead, hammerhead shark', 5: 'electric ray, crampfish, numbfish, torpedo', 6: 'stingray', 7: 'cock', 8: 'hen', 9: 'ostrich, Struthio camelus', 10: 'brambling, Fringilla montifringilla', 11: 'goldfinch, Carduelis carduelis', 12: 'house finch, linnet, Carpodacus mexicanus', 13: 'junco, snowbird', 14: 'indigo bunting, indigo finch, indigo bird, Passerina cyanea', 15: 'robin, American robin, Turdus migratorius', 16: 'bulbul', 17: 'jay', 18: 'magpie', 19: 'chickadee', 20: 'water ouzel, dipper', 21: 'kite', 22: 'bald eagle, American eagle, Haliaeetus leucocephalus', 23: 'vulture', 24: 'great grey owl, great gray owl, Strix nebulosa', 25: 'European fire salamander, Salamandra salamandra', 26: 'common newt, Triturus vulgaris', 27: 'eft', 28: 'spotted salamander, Ambystoma maculatum', 29: 'axolotl, mud puppy, Ambystoma mexicanum', 30: 'bullfrog, Rana catesbeiana', 31: 'tree frog, tree-frog', 32: 'tailed frog, bell toad, ribbed toad, tailed toad, Ascaphus trui', 33: 'loggerhead, loggerhead turtle, Caretta caretta', 34: 'leatherback turtle, leatherback, leathery turtle, Dermochelys coriacea', 35: 'mud turtle', 36: 'terrapin', 37: 'box turtle, box tortoise', 38: 'banded gecko', 39: 'common iguana, iguana, Iguana iguana', 40: 'American chameleon, anole, Anolis carolinensis', 41: 'whiptail, whiptail lizard', 42: 'agama', 43: 'frilled lizard, Chlamydosaurus kingi', 44: 'alligator lizard', 45: 'Gila monster, Heloderma suspectum', 46: 'green lizard, Lacerta viridis', 47: 'African chameleon, Chamaeleo chamaeleon', 48: 'Komodo dragon, Komodo lizard, dragon lizard, giant lizard, Varanus komodoensis', 49: 'African crocodile, Nile crocodile, Crocodylus niloticus', 50: 'American alligator, Alligator mississipiensis', 51: 'triceratops', 52: 'thunder snake, worm snake, Carphophis amoenus', 53: 'ringneck snake, ring-necked snake, ring snake', 54: 'hognose snake, puff adder, sand viper', 55: 'green snake, grass snake', 56: 'king snake, kingsnake', 57: 'garter snake, grass snake', 58: 'water snake', 59: 'vine snake', 60: 'night snake, Hypsiglena torquata', 61: 'boa constrictor, Constrictor constrictor', 62: 'rock python, rock snake, Python sebae', 63: 'Indian cobra, Naja naja', 64: 'green mamba', 65: 'sea snake', 66: 'horned viper, cerastes, sand viper, horned asp, Cerastes cornutus', 67: 'diamondback, diamondback rattlesnake, Crotalus adamanteus', 68: 'sidewinder, horned rattlesnake, Crotalus cerastes', 69: 'trilobite', 70: 'harvestman, daddy longlegs, Phalangium opilio', 71: 'scorpion', 72: 'black and gold garden spider, Argiope aurantia', 73: 'barn spider, Araneus cavaticus', 74: 'garden spider, Aranea diademata', 75: 'black widow, Latrodectus mactans', 76: 'tarantula', 77: 'wolf spider, hunting spider', 78: 'tick', 79: 'centipede', 80: 'black grouse', 81: 'ptarmigan', 82: 'ruffed grouse, partridge, Bonasa umbellus', 83: 'prairie chicken, prairie grouse, prairie fowl', 84: 'peacock', 85: 'quail', 86: 'partridge', 87: 'African grey, African gray, Psittacus erithacus', 88: 'macaw', 89: 'sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita', 90: 'lorikeet', 91: 'coucal', 92: 'bee eater', 93: 'hornbill', 94: 'hummingbird', 95: 'jacamar', 96: 'toucan', 97: 'drake', 98: 'red-breasted merganser, Mergus serrator', 99: 'goose', 100: 'black swan, Cygnus atratus', 101: 'tusker', 102: 'echidna, spiny anteater, anteater', 103: 'platypus, duckbill, duckbilled platypus, duck-billed platypus, Ornithorhynchus anatinus', 104: 'wallaby, brush kangaroo', 105: 'koala, koala bear, kangaroo bear, native bear, Phascolarctos cinereus', 106: 'wombat', 107: 'jellyfish', 108: 'sea anemone, anemone', 109: 'brain coral', 110: 'flatworm, platyhelminth', 111: 'nematode, nematode worm, roundworm', 112: 'conch', 113: 'snail', 114: 'slug', 115: 'sea slug, nudibranch', 116: 'chiton, coat-of-mail shell, sea cradle, polyplacophore', 117: 'chambered nautilus, pearly nautilus, nautilus', 118: 'Dungeness crab, Cancer magister', 119: 'rock crab, Cancer irroratus', 120: 'fiddler crab', 121: 'king crab, Alaska crab, Alaskan king crab, Alaska king crab, Paralithodes camtschatica', 122: 'American lobster, Northern lobster, Maine lobster, Homarus americanus', 123: 'spiny lobster, langouste, rock lobster, crawfish, crayfish, sea crawfish', 124: 'crayfish, crawfish, crawdad, crawdaddy', 125: 'hermit crab', 126: 'isopod', 127: 'white stork, Ciconia ciconia', 128: 'black stork, Ciconia nigra', 129: 'spoonbill', 130: 'flamingo', 131: 'little blue heron, Egretta caerulea', 132: 'American egret, great white heron, Egretta albus', 133: 'bittern', 134: 'crane', 135: 'limpkin, Aramus pictus', 136: 'European gallinule, Porphyrio porphyrio', 137: 'American coot, marsh hen, mud hen, water hen, Fulica americana', 138: 'bustard', 139: 'ruddy turnstone, Arenaria interpres', 140: 'red-backed sandpiper, dunlin, Erolia alpina', 141: 'redshank, Tringa totanus', 142: 'dowitcher', 143: 'oystercatcher, oyster catcher', 144: 'pelican', 145: 'king penguin, Aptenodytes patagonica', 146: 'albatross, mollymawk', 147: 'grey whale, gray whale, devilfish, Eschrichtius gibbosus, Eschrichtius robustus', 148: 'killer whale, killer, orca, grampus, sea wolf, Orcinus orca', 149: 'dugong, Dugong dugon', 150: 'sea lion', 151: 'Chihuahua', 152: 'Japanese spaniel', 153: 'Maltese dog, Maltese terrier, Maltese', 154: 'Pekinese, Pekingese, Peke', 155: 'Shih-Tzu', 156: 'Blenheim spaniel', 157: 'papillon', 158: 'toy terrier', 159: 'Rhodesian ridgeback', 160: 'Afghan hound, Afghan', 161: 'basset, basset hound', 162: 'beagle', 163: 'bloodhound, sleuthhound', 164: 'bluetick', 165: 'black-and-tan coonhound', 166: 'Walker hound, Walker foxhound', 167: 'English foxhound', 168: 'redbone', 169: 'borzoi, Russian wolfhound', 170: 'Irish wolfhound', 171: 'Italian greyhound', 172: 'whippet', 173: 'Ibizan hound, Ibizan Podenco', 174: 'Norwegian elkhound, elkhound', 175: 'otterhound, otter hound', 176: 'Saluki, gazelle hound', 177: 'Scottish deerhound, deerhound', 178: 'Weimaraner', 179: 'Staffordshire bullterrier, Staffordshire bull terrier', 180: 'American Staffordshire terrier, Staffordshire terrier, American pit bull terrier, pit bull terrier', 181: 'Bedlington terrier', 182: 'Border terrier', 183: 'Kerry blue terrier', 184: 'Irish terrier', 185: 'Norfolk terrier', 186: 'Norwich terrier', 187: 'Yorkshire terrier', 188: 'wire-haired fox terrier', 189: 'Lakeland terrier', 190: 'Sealyham terrier, Sealyham', 191: 'Airedale, Airedale terrier', 192: 'cairn, cairn terrier', 193: 'Australian terrier', 194: 'Dandie Dinmont, Dandie Dinmont terrier', 195: 'Boston bull, Boston terrier', 196: 'miniature schnauzer', 197: 'giant schnauzer', 198: 'standard schnauzer', 199: 'Scotch terrier, Scottish terrier, Scottie', 200: 'Tibetan terrier, chrysanthemum dog', 201: 'silky terrier, Sydney silky', 202: 'soft-coated wheaten terrier', 203: 'West Highland white terrier', 204: 'Lhasa, Lhasa apso', 205: 'flat-coated retriever', 206: 'curly-coated retriever', 207: 'golden retriever', 208: 'Labrador retriever', 209: 'Chesapeake Bay retriever', 210: 'German short-haired pointer', 211: 'vizsla, Hungarian pointer', 212: 'English setter', 213: 'Irish setter, red setter', 214: 'Gordon setter', 215: 'Brittany spaniel', 216: 'clumber, clumber spaniel', 217: 'English springer, English springer spaniel', 218: 'Welsh springer spaniel', 219: 'cocker spaniel, English cocker spaniel, cocker', 220: 'Sussex spaniel', 221: 'Irish water spaniel', 222: 'kuvasz', 223: 'schipperke', 224: 'groenendael', 225: 'malinois', 226: 'briard', 227: 'kelpie', 228: 'komondor', 229: 'Old English sheepdog, bobtail', 230: 'Shetland sheepdog, Shetland sheep dog, Shetland', 231: 'collie', 232: 'Border collie', 233: 'Bouvier des Flandres, Bouviers des Flandres', 234: 'Rottweiler', 235: 'German shepherd, German shepherd dog, German police dog, alsatian', 236: 'Doberman, Doberman pinscher', 237: 'miniature pinscher', 238: 'Greater Swiss Mountain dog', 239: 'Bernese mountain dog', 240: 'Appenzeller', 241: 'EntleBucher', 242: 'boxer', 243: 'bull mastiff', 244: 'Tibetan mastiff', 245: 'French bulldog', 246: 'Great Dane', 247: 'Saint Bernard, St Bernard', 248: 'Eskimo dog, husky', 249: 'malamute, malemute, Alaskan malamute', 250: 'Siberian husky', 251: 'dalmatian, coach dog, carriage dog', 252: 'affenpinscher, monkey pinscher, monkey dog', 253: 'basenji', 254: 'pug, pug-dog', 255: 'Leonberg', 256: 'Newfoundland, Newfoundland dog', 257: 'Great Pyrenees', 258: 'Samoyed, Samoyede', 259: 'Pomeranian', 260: 'chow, chow chow', 261: 'keeshond', 262: 'Brabancon griffon', 263: 'Pembroke, Pembroke Welsh corgi', 264: 'Cardigan, Cardigan Welsh corgi', 265: 'toy poodle', 266: 'miniature poodle', 267: 'standard poodle', 268: 'Mexican hairless', 269: 'timber wolf, grey wolf, gray wolf, Canis lupus', 270: 'white wolf, Arctic wolf, Canis lupus tundrarum', 271: 'red wolf, maned wolf, Canis rufus, Canis niger', 272: 'coyote, prairie wolf, brush wolf, Canis latrans', 273: 'dingo, warrigal, warragal, Canis dingo', 274: 'dhole, Cuon alpinus', 275: 'African hunting dog, hyena dog, Cape hunting dog, Lycaon pictus', 276: 'hyena, hyaena', 277: 'red fox, Vulpes vulpes', 278: 'kit fox, Vulpes macrotis', 279: 'Arctic fox, white fox, Alopex lagopus', 280: 'grey fox, gray fox, Urocyon cinereoargenteus', 281: 'tabby, tabby cat', 282: 'tiger cat', 283: 'Persian cat', 284: 'Siamese cat, Siamese', 285: 'Egyptian cat', 286: 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor', 287: 'lynx, catamount', 288: 'leopard, Panthera pardus', 289: 'snow leopard, ounce, Panthera uncia', 290: 'jaguar, panther, Panthera onca, Felis onca', 291: 'lion, king of beasts, Panthera leo', 292: 'tiger, Panthera tigris', 293: 'cheetah, chetah, Acinonyx jubatus', 294: 'brown bear, bruin, Ursus arctos', 295: 'American black bear, black bear, Ursus americanus, Euarctos americanus', 296: 'ice bear, polar bear, Ursus Maritimus, Thalarctos maritimus', 297: 'sloth bear, Melursus ursinus, Ursus ursinus', 298: 'mongoose', 299: 'meerkat, mierkat', 300: 'tiger beetle', 301: 'ladybug, ladybeetle, lady beetle, ladybird, ladybird beetle', 302: 'ground beetle, carabid beetle', 303: 'long-horned beetle, longicorn, longicorn beetle', 304: 'leaf beetle, chrysomelid', 305: 'dung beetle', 306: 'rhinoceros beetle', 307: 'weevil', 308: 'fly', 309: 'bee', 310: 'ant, emmet, pismire', 311: 'grasshopper, hopper', 312: 'cricket', 313: 'walking stick, walkingstick, stick insect', 314: 'cockroach, roach', 315: 'mantis, mantid', 316: 'cicada, cicala', 317: 'leafhopper', 318: 'lacewing, lacewing fly', 319: \"dragonfly, darning needle, devil's darning needle, sewing needle, snake feeder, snake doctor, mosquito hawk, skeeter hawk\", 320: 'damselfly', 321: 'admiral', 322: 'ringlet, ringlet butterfly', 323: 'monarch, monarch butterfly, milkweed butterfly, Danaus plexippus', 324: 'cabbage butterfly', 325: 'sulphur butterfly, sulfur butterfly', 326: 'lycaenid, lycaenid butterfly', 327: 'starfish, sea star', 328: 'sea urchin', 329: 'sea cucumber, holothurian', 330: 'wood rabbit, cottontail, cottontail rabbit', 331: 'hare', 332: 'Angora, Angora rabbit', 333: 'hamster', 334: 'porcupine, hedgehog', 335: 'fox squirrel, eastern fox squirrel, Sciurus niger', 336: 'marmot', 337: 'beaver', 338: 'guinea pig, Cavia cobaya', 339: 'sorrel', 340: 'zebra', 341: 'hog, pig, grunter, squealer, Sus scrofa', 342: 'wild boar, boar, Sus scrofa', 343: 'warthog', 344: 'hippopotamus, hippo, river horse, Hippopotamus amphibius', 345: 'ox', 346: 'water buffalo, water ox, Asiatic buffalo, Bubalus bubalis', 347: 'bison', 348: 'ram, tup', 349: 'bighorn, bighorn sheep, cimarron, Rocky Mountain bighorn, Rocky Mountain sheep, Ovis canadensis', 350: 'ibex, Capra ibex', 351: 'hartebeest', 352: 'impala, Aepyceros melampus', 353: 'gazelle', 354: 'Arabian camel, dromedary, Camelus dromedarius', 355: 'llama', 356: 'weasel', 357: 'mink', 358: 'polecat, fitch, foulmart, foumart, Mustela putorius', 359: 'black-footed ferret, ferret, Mustela nigripes', 360: 'otter', 361: 'skunk, polecat, wood pussy', 362: 'badger', 363: 'armadillo', 364: 'three-toed sloth, ai, Bradypus tridactylus', 365: 'orangutan, orang, orangutang, Pongo pygmaeus', 366: 'gorilla, Gorilla gorilla', 367: 'chimpanzee, chimp, Pan troglodytes', 368: 'gibbon, Hylobates lar', 369: 'siamang, Hylobates syndactylus, Symphalangus syndactylus', 370: 'guenon, guenon monkey', 371: 'patas, hussar monkey, Erythrocebus patas', 372: 'baboon', 373: 'macaque', 374: 'langur', 375: 'colobus, colobus monkey', 376: 'proboscis monkey, Nasalis larvatus', 377: 'marmoset', 378: 'capuchin, ringtail, Cebus capucinus', 379: 'howler monkey, howler', 380: 'titi, titi monkey', 381: 'spider monkey, Ateles geoffroyi', 382: 'squirrel monkey, Saimiri sciureus', 383: 'Madagascar cat, ring-tailed lemur, Lemur catta', 384: 'indri, indris, Indri indri, Indri brevicaudatus', 385: 'Indian elephant, Elephas maximus', 386: 'African elephant, Loxodonta africana', 387: 'lesser panda, red panda, panda, bear cat, cat bear, Ailurus fulgens', 388: 'giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca', 389: 'barracouta, snoek', 390: 'eel', 391: 'coho, cohoe, coho salmon, blue jack, silver salmon, Oncorhynchus kisutch', 392: 'rock beauty, Holocanthus tricolor', 393: 'anemone fish', 394: 'sturgeon', 395: 'gar, garfish, garpike, billfish, Lepisosteus osseus', 396: 'lionfish', 397: 'puffer, pufferfish, blowfish, globefish', 398: 'abacus', 399: 'abaya', 400: \"academic gown, academic robe, judge's robe\", 401: 'accordion, piano accordion, squeeze box', 402: 'acoustic guitar', 403: 'aircraft carrier, carrier, flattop, attack aircraft carrier', 404: 'airliner', 405: 'airship, dirigible', 406: 'altar', 407: 'ambulance', 408: 'amphibian, amphibious vehicle', 409: 'analog clock', 410: 'apiary, bee house', 411: 'apron', 412: 'ashcan, trash can, garbage can, wastebin, ash bin, ash-bin, ashbin, dustbin, trash barrel, trash bin', 413: 'assault rifle, assault gun', 414: 'backpack, back pack, knapsack, packsack, rucksack, haversack', 415: 'bakery, bakeshop, bakehouse', 416: 'balance beam, beam', 417: 'balloon', 418: 'ballpoint, ballpoint pen, ballpen, Biro', 419: 'Band Aid', 420: 'banjo', 421: 'bannister, banister, balustrade, balusters, handrail', 422: 'barbell', 423: 'barber chair', 424: 'barbershop', 425: 'barn', 426: 'barometer', 427: 'barrel, cask', 428: 'barrow, garden cart, lawn cart, wheelbarrow', 429: 'baseball', 430: 'basketball', 431: 'bassinet', 432: 'bassoon', 433: 'bathing cap, swimming cap', 434: 'bath towel', 435: 'bathtub, bathing tub, bath, tub', 436: 'beach wagon, station wagon, wagon, estate car, beach waggon, station waggon, waggon', 437: 'beacon, lighthouse, beacon light, pharos', 438: 'beaker', 439: 'bearskin, busby, shako', 440: 'beer bottle', 441: 'beer glass', 442: 'bell cote, bell cot', 443: 'bib', 444: 'bicycle-built-for-two, tandem bicycle, tandem', 445: 'bikini, two-piece', 446: 'binder, ring-binder', 447: 'binoculars, field glasses, opera glasses', 448: 'birdhouse', 449: 'boathouse', 450: 'bobsled, bobsleigh, bob', 451: 'bolo tie, bolo, bola tie, bola', 452: 'bonnet, poke bonnet', 453: 'bookcase', 454: 'bookshop, bookstore, bookstall', 455: 'bottlecap', 456: 'bow', 457: 'bow tie, bow-tie, bowtie', 458: 'brass, memorial tablet, plaque', 459: 'brassiere, bra, bandeau', 460: 'breakwater, groin, groyne, mole, bulwark, seawall, jetty', 461: 'breastplate, aegis, egis', 462: 'broom', 463: 'bucket, pail', 464: 'buckle', 465: 'bulletproof vest', 466: 'bullet train, bullet', 467: 'butcher shop, meat market', 468: 'cab, hack, taxi, taxicab', 469: 'caldron, cauldron', 470: 'candle, taper, wax light', 471: 'cannon', 472: 'canoe', 473: 'can opener, tin opener', 474: 'cardigan', 475: 'car mirror', 476: 'carousel, carrousel, merry-go-round, roundabout, whirligig', 477: \"carpenter's kit, tool kit\", 478: 'carton', 479: 'car wheel', 480: 'cash machine, cash dispenser, automated teller machine, automatic teller machine, automated teller, automatic teller, ATM', 481: 'cassette', 482: 'cassette player', 483: 'castle', 484: 'catamaran', 485: 'CD player', 486: 'cello, violoncello', 487: 'cellular telephone, cellular phone, cellphone, cell, mobile phone', 488: 'chain', 489: 'chainlink fence', 490: 'chain mail, ring mail, mail, chain armor, chain armour, ring armor, ring armour', 491: 'chain saw, chainsaw', 492: 'chest', 493: 'chiffonier, commode', 494: 'chime, bell, gong', 495: 'china cabinet, china closet', 496: 'Christmas stocking', 497: 'church, church building', 498: 'cinema, movie theater, movie theatre, movie house, picture palace', 499: 'cleaver, meat cleaver, chopper', 500: 'cliff dwelling', 501: 'cloak', 502: 'clog, geta, patten, sabot', 503: 'cocktail shaker', 504: 'coffee mug', 505: 'coffeepot', 506: 'coil, spiral, volute, whorl, helix', 507: 'combination lock', 508: 'computer keyboard, keypad', 509: 'confectionery, confectionary, candy store', 510: 'container ship, containership, container vessel', 511: 'convertible', 512: 'corkscrew, bottle screw', 513: 'cornet, horn, trumpet, trump', 514: 'cowboy boot', 515: 'cowboy hat, ten-gallon hat', 516: 'cradle', 517: 'crane', 518: 'crash helmet', 519: 'crate', 520: 'crib, cot', 521: 'Crock Pot', 522: 'croquet ball', 523: 'crutch', 524: 'cuirass', 525: 'dam, dike, dyke', 526: 'desk', 527: 'desktop computer', 528: 'dial telephone, dial phone', 529: 'diaper, nappy, napkin', 530: 'digital clock', 531: 'digital watch', 532: 'dining table, board', 533: 'dishrag, dishcloth', 534: 'dishwasher, dish washer, dishwashing machine', 535: 'disk brake, disc brake', 536: 'dock, dockage, docking facility', 537: 'dogsled, dog sled, dog sleigh', 538: 'dome', 539: 'doormat, welcome mat', 540: 'drilling platform, offshore rig', 541: 'drum, membranophone, tympan', 542: 'drumstick', 543: 'dumbbell', 544: 'Dutch oven', 545: 'electric fan, blower', 546: 'electric guitar', 547: 'electric locomotive', 548: 'entertainment center', 549: 'envelope', 550: 'espresso maker', 551: 'face powder', 552: 'feather boa, boa', 553: 'file, file cabinet, filing cabinet', 554: 'fireboat', 555: 'fire engine, fire truck', 556: 'fire screen, fireguard', 557: 'flagpole, flagstaff', 558: 'flute, transverse flute', 559: 'folding chair', 560: 'football helmet', 561: 'forklift', 562: 'fountain', 563: 'fountain pen', 564: 'four-poster', 565: 'freight car', 566: 'French horn, horn', 567: 'frying pan, frypan, skillet', 568: 'fur coat', 569: 'garbage truck, dustcart', 570: 'gasmask, respirator, gas helmet', 571: 'gas pump, gasoline pump, petrol pump, island dispenser', 572: 'goblet', 573: 'go-kart', 574: 'golf ball', 575: 'golfcart, golf cart', 576: 'gondola', 577: 'gong, tam-tam', 578: 'gown', 579: 'grand piano, grand', 580: 'greenhouse, nursery, glasshouse', 581: 'grille, radiator grille', 582: 'grocery store, grocery, food market, market', 583: 'guillotine', 584: 'hair slide', 585: 'hair spray', 586: 'half track', 587: 'hammer', 588: 'hamper', 589: 'hand blower, blow dryer, blow drier, hair dryer, hair drier', 590: 'hand-held computer, hand-held microcomputer', 591: 'handkerchief, hankie, hanky, hankey', 592: 'hard disc, hard disk, fixed disk', 593: 'harmonica, mouth organ, harp, mouth harp', 594: 'harp', 595: 'harvester, reaper', 596: 'hatchet', 597: 'holster', 598: 'home theater, home theatre', 599: 'honeycomb', 600: 'hook, claw', 601: 'hoopskirt, crinoline', 602: 'horizontal bar, high bar', 603: 'horse cart, horse-cart', 604: 'hourglass', 605: 'iPod', 606: 'iron, smoothing iron', 607: \"jack-o'-lantern\", 608: 'jean, blue jean, denim', 609: 'jeep, landrover', 610: 'jersey, T-shirt, tee shirt', 611: 'jigsaw puzzle', 612: 'jinrikisha, ricksha, rickshaw', 613: 'joystick', 614: 'kimono', 615: 'knee pad', 616: 'knot', 617: 'lab coat, laboratory coat', 618: 'ladle', 619: 'lampshade, lamp shade', 620: 'laptop, laptop computer', 621: 'lawn mower, mower', 622: 'lens cap, lens cover', 623: 'letter opener, paper knife, paperknife', 624: 'library', 625: 'lifeboat', 626: 'lighter, light, igniter, ignitor', 627: 'limousine, limo', 628: 'liner, ocean liner', 629: 'lipstick, lip rouge', 630: 'Loafer', 631: 'lotion', 632: 'loudspeaker, speaker, speaker unit, loudspeaker system, speaker system', 633: \"loupe, jeweler's loupe\", 634: 'lumbermill, sawmill', 635: 'magnetic compass', 636: 'mailbag, postbag', 637: 'mailbox, letter box', 638: 'maillot', 639: 'maillot, tank suit', 640: 'manhole cover', 641: 'maraca', 642: 'marimba, xylophone', 643: 'mask', 644: 'matchstick', 645: 'maypole', 646: 'maze, labyrinth', 647: 'measuring cup', 648: 'medicine chest, medicine cabinet', 649: 'megalith, megalithic structure', 650: 'microphone, mike', 651: 'microwave, microwave oven', 652: 'military uniform', 653: 'milk can', 654: 'minibus', 655: 'miniskirt, mini', 656: 'minivan', 657: 'missile', 658: 'mitten', 659: 'mixing bowl', 660: 'mobile home, manufactured home', 661: 'Model T', 662: 'modem', 663: 'monastery', 664: 'monitor', 665: 'moped', 666: 'mortar', 667: 'mortarboard', 668: 'mosque', 669: 'mosquito net', 670: 'motor scooter, scooter', 671: 'mountain bike, all-terrain bike, off-roader', 672: 'mountain tent', 673: 'mouse, computer mouse', 674: 'mousetrap', 675: 'moving van', 676: 'muzzle', 677: 'nail', 678: 'neck brace', 679: 'necklace', 680: 'nipple', 681: 'notebook, notebook computer', 682: 'obelisk', 683: 'oboe, hautboy, hautbois', 684: 'ocarina, sweet potato', 685: 'odometer, hodometer, mileometer, milometer', 686: 'oil filter', 687: 'organ, pipe organ', 688: 'oscilloscope, scope, cathode-ray oscilloscope, CRO', 689: 'overskirt', 690: 'oxcart', 691: 'oxygen mask', 692: 'packet', 693: 'paddle, boat paddle', 694: 'paddlewheel, paddle wheel', 695: 'padlock', 696: 'paintbrush', 697: \"pajama, pyjama, pj's, jammies\", 698: 'palace', 699: 'panpipe, pandean pipe, syrinx', 700: 'paper towel', 701: 'parachute, chute', 702: 'parallel bars, bars', 703: 'park bench', 704: 'parking meter', 705: 'passenger car, coach, carriage', 706: 'patio, terrace', 707: 'pay-phone, pay-station', 708: 'pedestal, plinth, footstall', 709: 'pencil box, pencil case', 710: 'pencil sharpener', 711: 'perfume, essence', 712: 'Petri dish', 713: 'photocopier', 714: 'pick, plectrum, plectron', 715: 'pickelhaube', 716: 'picket fence, paling', 717: 'pickup, pickup truck', 718: 'pier', 719: 'piggy bank, penny bank', 720: 'pill bottle', 721: 'pillow', 722: 'ping-pong ball', 723: 'pinwheel', 724: 'pirate, pirate ship', 725: 'pitcher, ewer', 726: \"plane, carpenter's plane, woodworking plane\", 727: 'planetarium', 728: 'plastic bag', 729: 'plate rack', 730: 'plow, plough', 731: \"plunger, plumber's helper\", 732: 'Polaroid camera, Polaroid Land camera', 733: 'pole', 734: 'police van, police wagon, paddy wagon, patrol wagon, wagon, black Maria', 735: 'poncho', 736: 'pool table, billiard table, snooker table', 737: 'pop bottle, soda bottle', 738: 'pot, flowerpot', 739: \"potter's wheel\", 740: 'power drill', 741: 'prayer rug, prayer mat', 742: 'printer', 743: 'prison, prison house', 744: 'projectile, missile', 745: 'projector', 746: 'puck, hockey puck', 747: 'punching bag, punch bag, punching ball, punchball', 748: 'purse', 749: 'quill, quill pen', 750: 'quilt, comforter, comfort, puff', 751: 'racer, race car, racing car', 752: 'racket, racquet', 753: 'radiator', 754: 'radio, wireless', 755: 'radio telescope, radio reflector', 756: 'rain barrel', 757: 'recreational vehicle, RV, R.V.', 758: 'reel', 759: 'reflex camera', 760: 'refrigerator, icebox', 761: 'remote control, remote', 762: 'restaurant, eating house, eating place, eatery', 763: 'revolver, six-gun, six-shooter', 764: 'rifle', 765: 'rocking chair, rocker', 766: 'rotisserie', 767: 'rubber eraser, rubber, pencil eraser', 768: 'rugby ball', 769: 'rule, ruler', 770: 'running shoe', 771: 'safe', 772: 'safety pin', 773: 'saltshaker, salt shaker', 774: 'sandal', 775: 'sarong', 776: 'sax, saxophone', 777: 'scabbard', 778: 'scale, weighing machine', 779: 'school bus', 780: 'schooner', 781: 'scoreboard', 782: 'screen, CRT screen', 783: 'screw', 784: 'screwdriver', 785: 'seat belt, seatbelt', 786: 'sewing machine', 787: 'shield, buckler', 788: 'shoe shop, shoe-shop, shoe store', 789: 'shoji', 790: 'shopping basket', 791: 'shopping cart', 792: 'shovel', 793: 'shower cap', 794: 'shower curtain', 795: 'ski', 796: 'ski mask', 797: 'sleeping bag', 798: 'slide rule, slipstick', 799: 'sliding door', 800: 'slot, one-armed bandit', 801: 'snorkel', 802: 'snowmobile', 803: 'snowplow, snowplough', 804: 'soap dispenser', 805: 'soccer ball', 806: 'sock', 807: 'solar dish, solar collector, solar furnace', 808: 'sombrero', 809: 'soup bowl', 810: 'space bar', 811: 'space heater', 812: 'space shuttle', 813: 'spatula', 814: 'speedboat', 815: \"spider web, spider's web\", 816: 'spindle', 817: 'sports car, sport car', 818: 'spotlight, spot', 819: 'stage', 820: 'steam locomotive', 821: 'steel arch bridge', 822: 'steel drum', 823: 'stethoscope', 824: 'stole', 825: 'stone wall', 826: 'stopwatch, stop watch', 827: 'stove', 828: 'strainer', 829: 'streetcar, tram, tramcar, trolley, trolley car', 830: 'stretcher', 831: 'studio couch, day bed', 832: 'stupa, tope', 833: 'submarine, pigboat, sub, U-boat', 834: 'suit, suit of clothes', 835: 'sundial', 836: 'sunglass', 837: 'sunglasses, dark glasses, shades', 838: 'sunscreen, sunblock, sun blocker', 839: 'suspension bridge', 840: 'swab, swob, mop', 841: 'sweatshirt', 842: 'swimming trunks, bathing trunks', 843: 'swing', 844: 'switch, electric switch, electrical switch', 845: 'syringe', 846: 'table lamp', 847: 'tank, army tank, armored combat vehicle, armoured combat vehicle', 848: 'tape player', 849: 'teapot', 850: 'teddy, teddy bear', 851: 'television, television system', 852: 'tennis ball', 853: 'thatch, thatched roof', 854: 'theater curtain, theatre curtain', 855: 'thimble', 856: 'thresher, thrasher, threshing machine', 857: 'throne', 858: 'tile roof', 859: 'toaster', 860: 'tobacco shop, tobacconist shop, tobacconist', 861: 'toilet seat', 862: 'torch', 863: 'totem pole', 864: 'tow truck, tow car, wrecker', 865: 'toyshop', 866: 'tractor', 867: 'trailer truck, tractor trailer, trucking rig, rig, articulated lorry, semi', 868: 'tray', 869: 'trench coat', 870: 'tricycle, trike, velocipede', 871: 'trimaran', 872: 'tripod', 873: 'triumphal arch', 874: 'trolleybus, trolley coach, trackless trolley', 875: 'trombone', 876: 'tub, vat', 877: 'turnstile', 878: 'typewriter keyboard', 879: 'umbrella', 880: 'unicycle, monocycle', 881: 'upright, upright piano', 882: 'vacuum, vacuum cleaner', 883: 'vase', 884: 'vault', 885: 'velvet', 886: 'vending machine', 887: 'vestment', 888: 'viaduct', 889: 'violin, fiddle', 890: 'volleyball', 891: 'waffle iron', 892: 'wall clock', 893: 'wallet, billfold, notecase, pocketbook', 894: 'wardrobe, closet, press', 895: 'warplane, military plane', 896: 'washbasin, handbasin, washbowl, lavabo, wash-hand basin', 897: 'washer, automatic washer, washing machine', 898: 'water bottle', 899: 'water jug', 900: 'water tower', 901: 'whiskey jug', 902: 'whistle', 903: 'wig', 904: 'window screen', 905: 'window shade', 906: 'Windsor tie', 907: 'wine bottle', 908: 'wing', 909: 'wok', 910: 'wooden spoon', 911: 'wool, woolen, woollen', 912: 'worm fence, snake fence, snake-rail fence, Virginia fence', 913: 'wreck', 914: 'yawl', 915: 'yurt', 916: 'web site, website, internet site, site', 917: 'comic book', 918: 'crossword puzzle, crossword', 919: 'street sign', 920: 'traffic light, traffic signal, stoplight', 921: 'book jacket, dust cover, dust jacket, dust wrapper', 922: 'menu', 923: 'plate', 924: 'guacamole', 925: 'consomme', 926: 'hot pot, hotpot', 927: 'trifle', 928: 'ice cream, icecream', 929: 'ice lolly, lolly, lollipop, popsicle', 930: 'French loaf', 931: 'bagel, beigel', 932: 'pretzel', 933: 'cheeseburger', 934: 'hotdog, hot dog, red hot', 935: 'mashed potato', 936: 'head cabbage', 937: 'broccoli', 938: 'cauliflower', 939: 'zucchini, courgette', 940: 'spaghetti squash', 941: 'acorn squash', 942: 'butternut squash', 943: 'cucumber, cuke', 944: 'artichoke, globe artichoke', 945: 'bell pepper', 946: 'cardoon', 947: 'mushroom', 948: 'Granny Smith', 949: 'strawberry', 950: 'orange', 951: 'lemon', 952: 'fig', 953: 'pineapple, ananas', 954: 'banana', 955: 'jackfruit, jak, jack', 956: 'custard apple', 957: 'pomegranate', 958: 'hay', 959: 'carbonara', 960: 'chocolate sauce, chocolate syrup', 961: 'dough', 962: 'meat loaf, meatloaf', 963: 'pizza, pizza pie', 964: 'potpie', 965: 'burrito', 966: 'red wine', 967: 'espresso', 968: 'cup', 969: 'eggnog', 970: 'alp', 971: 'bubble', 972: 'cliff, drop, drop-off', 973: 'coral reef', 974: 'geyser', 975: 'lakeside, lakeshore', 976: 'promontory, headland, head, foreland', 977: 'sandbar, sand bar', 978: 'seashore, coast, seacoast, sea-coast', 979: 'valley, vale', 980: 'volcano', 981: 'ballplayer, baseball player', 982: 'groom, bridegroom', 983: 'scuba diver', 984: 'rapeseed', 985: 'daisy', 986: \"yellow lady's slipper, yellow lady-slipper, Cypripedium calceolus, Cypripedium parviflorum\", 987: 'corn', 988: 'acorn', 989: 'hip, rose hip, rosehip', 990: 'buckeye, horse chestnut, conker', 991: 'coral fungus', 992: 'agaric', 993: 'gyromitra', 994: 'stinkhorn, carrion fungus', 995: 'earthstar', 996: 'hen-of-the-woods, hen of the woods, Polyporus frondosus, Grifola frondosa', 997: 'bolete', 998: 'ear, spike, capitulum', 999: 'toilet tissue, toilet paper, bathroom tissue'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32VV8XfaXV-F"
      },
      "source": [
        "*classification* of a single image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXTQudh1XRFV",
        "outputId": "d9c38742-1a61-4439-e36d-c13d5b0830c7"
      },
      "source": [
        "# your file name\n",
        "img_file = './drive/My Drive/public/data/images/cat_224.jpg'\n",
        "\n",
        "input_img = load_img(img_file) # prepare an jpg image for the model\n",
        "input_data = transform_img(input_img).to(device) # 3x400x225 -> 3x331x331 size may differ\n",
        "input_data = input_data.unsqueeze(0)           # 3x331x331 -> 1x3x331x331\n",
        "\n",
        "output_logits = model(input_data) # 1x1000\n",
        "\n",
        "print(\"{} is [{}: {}]\".format(img_file ,output_logits.argmax(),\n",
        "                           imagenet_class[int(output_logits.argmax())]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./drive/My Drive/public/data/images/cat_224.jpg is [3: tiger shark, Galeocerdo cuvieri]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TKvB3uinacI"
      },
      "source": [
        "classification of all the files in a directory\n",
        "./drive/My Drive/public/data/images/\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5J7WxXI9kzbr",
        "outputId": "ef6b1101-6519-49ef-b45f-1c85a8523036"
      },
      "source": [
        "import glob\n",
        "dir_path = './drive/My Drive/public/data/images/'\n",
        "img_list = glob.glob(dir_path+'*.*')\n",
        "\n",
        "for img_file in img_list:\n",
        "  input_img = load_img(img_file)\n",
        "  input_data = transform_img(input_img).to(device) # -> 3x331x331\n",
        "  input_data = input_data.unsqueeze(0)    # 3x331x331 -> 1x3x331x331\n",
        "  \n",
        "  output_logits = model(input_data) # 1x1000\n",
        "\n",
        "  print(\"{} is [{}: {}]\".format(img_file.split('/')[-1] ,output_logits.argmax(),\n",
        "                           imagenet_class[int(output_logits.argmax())]))\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test_0.jpg is [49: African crocodile, Nile crocodile, Crocodylus niloticus]\n",
            "test_1.jpg is [282: tiger cat]\n",
            "cat_224.jpg is [282: tiger cat]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFdB5qCOWHiz"
      },
      "source": [
        "# **Transfer** **Learning**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMFCwTEXW30W"
      },
      "source": [
        "Let's see our pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GFtxOO3WGMm",
        "outputId": "b89f2eac-66d5-4d15-eed1-ad4c0b8c7974"
      },
      "source": [
        "print(model)\n",
        "model.last_linear.in_features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NASNetALarge(\n",
            "  (conv0): Sequential(\n",
            "    (conv): Conv2d(3, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
            "    (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (cell_stem_0): CellStem0(\n",
            "    (conv_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(96, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(42, 42, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=42, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(42, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(42, 42, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=42, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(42, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_right): BranchSeparablesStem(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(96, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=96, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(96, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(42, 42, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=42, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(42, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_left): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (comb_iter_1_right): BranchSeparablesStem(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(96, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=96, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(96, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(42, 42, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=42, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(42, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "    (comb_iter_2_right): BranchSeparablesStem(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(96, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(42, 42, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=42, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(42, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_4_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(42, 42, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=42, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(42, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(42, 42, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=42, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(42, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(42, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_4_right): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (cell_stem_1): CellStem1(\n",
            "    (conv_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(168, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (relu): ReLU()\n",
            "    (path_1): Sequential(\n",
            "      (avgpool): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
            "      (conv): Conv2d(96, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (path_2): ModuleList(\n",
            "      (pad): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
            "      (avgpool): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
            "      (conv): Conv2d(96, 42, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (final_path_bn): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (comb_iter_0_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(84, 84, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=84, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(84, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(84, 84, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=84, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(84, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(84, 84, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=84, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(84, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(84, 84, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=84, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(84, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_left): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (comb_iter_1_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(84, 84, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=84, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(84, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(84, 84, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=84, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(84, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "    (comb_iter_2_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(84, 84, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=84, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(84, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(84, 84, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=84, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(84, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_4_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(84, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=84, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(84, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(84, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=84, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(84, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(84, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_4_right): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (cell_0): FirstCell(\n",
            "    (conv_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(336, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (relu): ReLU()\n",
            "    (path_1): Sequential(\n",
            "      (avgpool): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
            "      (conv): Conv2d(168, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (path_2): ModuleList(\n",
            "      (pad): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
            "      (avgpool): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
            "      (conv): Conv2d(168, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (final_path_bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (comb_iter_0_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_4_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (cell_1): NormalCell(\n",
            "    (conv_prev_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(336, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(1008, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_4_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (cell_2): NormalCell(\n",
            "    (conv_prev_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(1008, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(1008, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_4_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (cell_3): NormalCell(\n",
            "    (conv_prev_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(1008, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(1008, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_4_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (cell_4): NormalCell(\n",
            "    (conv_prev_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(1008, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(1008, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_4_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (cell_5): NormalCell(\n",
            "    (conv_prev_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(1008, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(1008, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_4_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(168, 168, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=168, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(168, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(168, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (reduction_cell_0): ReductionCell0(\n",
            "    (conv_prev_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(1008, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(1008, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_left): BranchSeparablesReduction(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (padding): ZeroPad2d(padding=(1, 0, 1, 0), value=0.0)\n",
            "    )\n",
            "    (comb_iter_0_right): BranchSeparablesReduction(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (padding): ZeroPad2d(padding=(1, 0, 1, 0), value=0.0)\n",
            "    )\n",
            "    (comb_iter_1_left): MaxPoolPad(\n",
            "      (pad): ZeroPad2d(padding=(1, 0, 1, 0), value=0.0)\n",
            "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (comb_iter_1_right): BranchSeparablesReduction(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (padding): ZeroPad2d(padding=(1, 0, 1, 0), value=0.0)\n",
            "    )\n",
            "    (comb_iter_2_left): AvgPoolPad(\n",
            "      (pad): ZeroPad2d(padding=(1, 0, 1, 0), value=0.0)\n",
            "      (pool): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "    )\n",
            "    (comb_iter_2_right): BranchSeparablesReduction(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (padding): ZeroPad2d(padding=(1, 0, 1, 0), value=0.0)\n",
            "    )\n",
            "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_4_left): BranchSeparablesReduction(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (padding): ZeroPad2d(padding=(1, 0, 1, 0), value=0.0)\n",
            "    )\n",
            "    (comb_iter_4_right): MaxPoolPad(\n",
            "      (pad): ZeroPad2d(padding=(1, 0, 1, 0), value=0.0)\n",
            "      (pool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "  )\n",
            "  (cell_6): FirstCell(\n",
            "    (conv_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(1344, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (relu): ReLU()\n",
            "    (path_1): Sequential(\n",
            "      (avgpool): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
            "      (conv): Conv2d(1008, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (path_2): ModuleList(\n",
            "      (pad): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
            "      (avgpool): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
            "      (conv): Conv2d(1008, 168, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (final_path_bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (comb_iter_0_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_4_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (cell_7): NormalCell(\n",
            "    (conv_prev_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(1344, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(2016, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_4_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (cell_8): NormalCell(\n",
            "    (conv_prev_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(2016, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(2016, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_4_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (cell_9): NormalCell(\n",
            "    (conv_prev_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(2016, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(2016, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_4_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (cell_10): NormalCell(\n",
            "    (conv_prev_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(2016, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(2016, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_4_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (cell_11): NormalCell(\n",
            "    (conv_prev_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(2016, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(2016, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_4_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(336, 336, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=336, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(336, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(336, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (reduction_cell_1): ReductionCell1(\n",
            "    (conv_prev_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(2016, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(2016, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_left): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (comb_iter_1_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=2, padding=1)\n",
            "    (comb_iter_2_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_4_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_4_right): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (cell_12): FirstCell(\n",
            "    (conv_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(2688, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (relu): ReLU()\n",
            "    (path_1): Sequential(\n",
            "      (avgpool): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
            "      (conv): Conv2d(2016, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (path_2): ModuleList(\n",
            "      (pad): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
            "      (avgpool): AvgPool2d(kernel_size=1, stride=2, padding=0)\n",
            "      (conv): Conv2d(2016, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (final_path_bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (comb_iter_0_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_4_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (cell_13): NormalCell(\n",
            "    (conv_prev_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(2688, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(4032, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_4_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (cell_14): NormalCell(\n",
            "    (conv_prev_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(4032, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(4032, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_4_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (cell_15): NormalCell(\n",
            "    (conv_prev_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(4032, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(4032, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_4_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (cell_16): NormalCell(\n",
            "    (conv_prev_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(4032, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(4032, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_4_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (cell_17): NormalCell(\n",
            "    (conv_prev_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(4032, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (conv_1x1): Sequential(\n",
            "      (relu): ReLU()\n",
            "      (conv): Conv2d(4032, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_0_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_1_right): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (comb_iter_2_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_left): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_3_right): AvgPool2d(kernel_size=3, stride=1, padding=1)\n",
            "    (comb_iter_4_left): BranchSeparables(\n",
            "      (relu): ReLU()\n",
            "      (separable_1): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu1): ReLU()\n",
            "      (separable_2): SeparableConv2d(\n",
            "        (depthwise_conv2d): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
            "        (pointwise_conv2d): Conv2d(672, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      )\n",
            "      (bn_sep_2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (relu): ReLU()\n",
            "  (avg_pool): AvgPool2d(kernel_size=11, stride=1, padding=0)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (last_linear): Linear(in_features=4032, out_features=1000, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4032"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gee-gFZfWboE"
      },
      "source": [
        "**We want to reuse pre-trained model's parameters except the 'last_linear' layer**\n",
        "\n",
        "Let's redefine the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMxQ9217Z2HA"
      },
      "source": [
        "from pretrainedmodels.models.nasnet import NASNetALarge \n",
        "output_dim = 5\n",
        "\n",
        "class TransferedModel(NASNetALarge) : \n",
        "  def __init__(self):\n",
        "    super(TransferedModel, self).__init__()\n",
        "    \n",
        "    self.last_linear = nn.Linear(model.last_linear.in_features, output_dim) # "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOA0CuYadtJV"
      },
      "source": [
        "we train only the 'last_linear' layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHlJAAPOXBAJ"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "pretrained_dict = model.state_dict()\n",
        "\n",
        "model = TransferedModel().to(device)\n",
        "model_dict = model.state_dict()\n",
        "\n",
        "## load pretrained model's parameter\n",
        "# 1. filter out unnecessary keys\n",
        "pretrained_dict = {k: v for k, v in pretrained_dict.items() if not ('last_linear' in k) }\n",
        "# 2. overwrite entries in the existing state dict\n",
        "model_dict.update(pretrained_dict)\n",
        "# 3. load the new state dict\n",
        "model.load_state_dict(model_dict)\n",
        "# why updating the state_dict?\n",
        "learning_rate = 0.0005\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "## optimizer without pretrained parameters\n",
        "# try training also the (last-1)th layer \n",
        "for name, param in model.named_parameters() :\n",
        "  if 'last_linear' in name :\n",
        "    param.requires_grad = True\n",
        "  else :\n",
        "    param.requires_grad = False\n",
        "params = filter(lambda p: p.requires_grad, model.parameters()) # only iterates through p.requires_grad == True elements\n",
        "optimizer = torch.optim.Adam(params, lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRCK6djOj-ax"
      },
      "source": [
        "\n",
        "\n",
        "*   data loader\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbMAWLWEkCVZ",
        "outputId": "7c7bbbb3-4d08-4f36-9c7c-7e97e1c3d74a"
      },
      "source": [
        "from torchvision import datasets\n",
        "\n",
        "batch_size = 64 # try different batch_size values\n",
        "data_dir = './drive/My Drive/public/'\n",
        "train_dir = 'train'\n",
        "valid_dir = 'valid'\n",
        "\n",
        "train_set = datasets.ImageFolder(data_dir+train_dir, transform_img)\n",
        "valid_set = datasets.ImageFolder(data_dir+valid_dir, transform_img)\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size,\n",
        "                                              shuffle=True, num_workers=4)          \n",
        "valid_loader = torch.utils.data.DataLoader(valid_set, batch_size=batch_size,\n",
        "                                              shuffle=True, num_workers=4)\n",
        "\n",
        "train_size = len(train_set)\n",
        "valid_size = len(valid_set)\n",
        "\n",
        "class_names = train_set.classes\n",
        "\n",
        "print(class_names) \n",
        "print(f'Train image size: {train_size}')\n",
        "print(f'Validation image size: {valid_size}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ANH', 'HDH', 'Hyoam', 'NTH', 'OH']\n",
            "Train image size: 4054\n",
            "Validation image size: 241\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI7ZZXOnkoM8"
      },
      "source": [
        "\n",
        "\n",
        "*   training the new network with new dataset\n",
        " * this takes some time (less than 10 min)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l46Jz3irkndD",
        "outputId": "aaa6d95a-cb13-429c-864c-c5bd4c7be79c"
      },
      "source": [
        "import os\n",
        "\n",
        "result_dir = 'drive/My Drive/public/results/'\n",
        "num_epoch = 3 # try with different epochs and find the best epoch\n",
        "\n",
        "if not os.path.exists(result_dir):\n",
        "    os.mkdir(result_dir)    \n",
        "    \n",
        "for i in range(num_epoch):\n",
        "    model.train()\n",
        "    for j, [image,label] in enumerate(train_loader):\n",
        "        x = image.to(device)\n",
        "        y_= label.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model(x)\n",
        "        loss = loss_func(output,y_)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if j % 30 == 0:\n",
        "            print(i,j, loss.data.cpu())\n",
        "    \n",
        "    model.eval()\n",
        "    hits = 0\n",
        "    for k, [image,label] in enumerate(valid_loader):\n",
        "        x = image.to(device)\n",
        "        y_= label.to(device)\n",
        "\n",
        "        output = model(x)\n",
        "        y_est = output.argmax(1)\n",
        "        hits = hits + sum(y_est == y_).cpu()\n",
        "    print('Hits', int(hits), 'Accuracy', float(hits/(valid_size+0.0)))    \n",
        "\n",
        "torch.save(model, result_dir + 'teamX.model')\n",
        "print('training is done by max_epochs', num_epoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0 tensor(1.6408)\n",
            "0 30 tensor(0.4788)\n",
            "0 60 tensor(0.2797)\n",
            "Hits 232 Accuracy 0.9626556038856506\n",
            "1 0 tensor(0.1959)\n",
            "1 30 tensor(0.1751)\n",
            "1 60 tensor(0.1145)\n",
            "Hits 228 Accuracy 0.9460580945014954\n",
            "2 0 tensor(0.1356)\n",
            "2 30 tensor(0.1104)\n",
            "2 60 tensor(0.1264)\n",
            "Hits 233 Accuracy 0.9668049812316895\n",
            "training is done by max_epochs 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWmOg2Ysk5GA"
      },
      "source": [
        "\n",
        "\n",
        "*   test your model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0HQb5b3mLlh",
        "outputId": "a4131713-75d9-4060-e50f-2024f314da92"
      },
      "source": [
        "test_batch_size = 10\n",
        "result_dir = 'drive/My Drive/public/results/'\n",
        "model_name = 'teamX.model'\n",
        "\n",
        "model = torch.load(result_dir + model_name)\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "test_dir = './drive/My Drive/public/valid2'\n",
        "test_set = datasets.ImageFolder(test_dir, transform_img) #test_transform)\n",
        "              \n",
        "test_loader = torch.utils.data.DataLoader(test_set, batch_size=test_batch_size,\n",
        "                                          shuffle=False, num_workers=4)\n",
        "\n",
        "hits = 0\n",
        "for k,[image,label] in enumerate(test_loader):\n",
        "    x = image.to(device)\n",
        "    y_= label.to(device)\n",
        "  \n",
        "    output = model(x)\n",
        "    y_est = output.argmax(1)\n",
        "    print('Target', label.numpy(), 'Prediction', y_est.cpu().numpy())\n",
        "    hits = hits + sum(y_est == y_)\n",
        "print('hits', int(hits),'accuracy', float(hits/(len(test_set)+0.0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Target [0 0 0 0 0 0 0 0 0 0] Prediction [0 0 0 0 0 0 0 0 0 0]\n",
            "Target [0 0 0 0 0 0 0 0 0 0] Prediction [0 0 0 0 0 0 0 0 0 0]\n",
            "Target [0 0 0 0 0 0 0 0 0 0] Prediction [0 0 0 0 0 0 0 0 0 0]\n",
            "Target [0 0 0 0 0 0 0 0 0 0] Prediction [0 0 0 0 0 0 0 0 0 0]\n",
            "Target [1 1 1 1 1 1 1 1 1 1] Prediction [1 1 1 1 1 1 1 1 1 1]\n",
            "Target [1 1 1 1 1 1 1 1 1 1] Prediction [1 1 1 1 1 1 1 1 1 1]\n",
            "Target [1 1 1 1 1 1 1 1 1 1] Prediction [1 1 1 1 1 1 1 1 1 1]\n",
            "Target [1 1 1 1 1 1 1 1 1 1] Prediction [1 1 1 1 1 3 1 1 1 1]\n",
            "Target [2 2 2 2 2 2 2 2 2 2] Prediction [2 2 2 2 2 2 2 2 2 2]\n",
            "Target [3 3 3 3 3 3 3 3 3 3] Prediction [3 3 3 3 3 3 3 3 3 3]\n",
            "Target [4 4 4 4 4 4 4 4 4 4] Prediction [4 4 4 4 3 4 3 3 4 3]\n",
            "hits 105 accuracy 0.9545454382896423\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ivf0WDhnmRGh"
      },
      "source": [
        "\n",
        "\n",
        "*   classify one image\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqNXMwxfmZS8",
        "outputId": "c4452f13-946d-46fb-b04d-cf5d81b96c8f"
      },
      "source": [
        "from skimage import io\n",
        "from torchvision import transforms\n",
        "\n",
        "img_name = './drive/My Drive/public/test/test1.jpg'\n",
        "test_img = io.imread(img_name)\n",
        "test_img = transforms.ToPILImage()(test_img)\n",
        "test_data = transform_img(test_img).unsqueeze(0).to(device)\n",
        "\n",
        "output=model(test_data)\n",
        "\n",
        "class_id = output.argmax(dim=1).cpu().numpy()[0]\n",
        "print(img_name.split('/')[-1], '==>', class_id, class_names[class_id])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test1.jpg ==> 0 ANH\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW2wxWCTmbi7"
      },
      "source": [
        "\n",
        "\n",
        "*   classify all images in a directory\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_nE8ywxmf1m",
        "outputId": "06dad7da-bc6c-4129-8da7-06a63810cc8d"
      },
      "source": [
        "from skimage import io\n",
        "import glob\n",
        "\n",
        "img_dir = 'drive/My Drive/public/test/'\n",
        "file_list = glob.glob(img_dir + '*.*')\n",
        "for img_name in file_list:\n",
        "  test_img = io.imread(img_name)\n",
        "  test_img = transforms.ToPILImage()(test_img)\n",
        "  test_data = transform_img(test_img).unsqueeze(0).to(device)\n",
        "  output=model(test_data)\n",
        "\n",
        "  class_id = output.argmax(dim=1).cpu().numpy()[0]\n",
        "  print(img_name.split('/')[-1], '==>', class_id, class_names[class_id])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "D08_ANH23.jpg ==> 0 ANH\n",
            "D13_ANH01.jpg ==> 0 ANH\n",
            "D17_Hyoam39.jpeg ==> 2 Hyoam\n",
            "D18_Hyoam40.JPG ==> 2 Hyoam\n",
            "D10_ANH46.jpg ==> 0 ANH\n",
            "D06_ANH32.jpg ==> 0 ANH\n",
            "test1.jpg ==> 0 ANH\n",
            "D12_AHN36.jpg ==> 0 ANH\n",
            "D10_ANH09.jpg ==> 0 ANH\n",
            "D06_HDH08.jpg ==> 1 HDH\n",
            "D15_HDH04.JPG ==> 1 HDH\n",
            "D06_OH29.jpg ==> 4 OH\n",
            "D05_NTH03.jpg ==> 3 NTH\n",
            "D08_OH29.jpg ==> 4 OH\n",
            "D07_HDH17.jpg ==> 1 HDH\n",
            "D18_NTH30.jpg ==> 3 NTH\n",
            "D11_NTH15.jpeg ==> 3 NTH\n",
            "D09_Hyoam09.JPG ==> 2 Hyoam\n",
            "D14_Hyoam12.jpg ==> 2 Hyoam\n",
            "D15_OH43.jpg ==> 4 OH\n",
            "D11_Hyoam05.JPG ==> 2 Hyoam\n",
            "D04_OH18.jpeg ==> 4 OH\n",
            "D01_Hyoam41.jpg ==> 2 Hyoam\n",
            "D05_NTH31.jpg ==> 3 NTH\n",
            "D13_NTH30.jpg ==> 3 NTH\n",
            "D07_HDH49.jpg ==> 1 HDH\n",
            "D16_OH34.jpg ==> 4 OH\n",
            "D07_HDH45.jpg ==> 1 HDH\n",
            "D14_OH12.jpg ==> 4 OH\n",
            "D02_HDH50.jpg ==> 1 HDH\n",
            "D15_Hyoam47.jpg ==> 2 Hyoam\n",
            "D07_HDH07.jpg ==> 3 NTH\n",
            "D13_ANH47.jpg ==> 1 HDH\n",
            "D15_OH31.jpg ==> 4 OH\n",
            "D01_OH22.jpg ==> 4 OH\n",
            "D12_NTH15.jpg ==> 3 NTH\n",
            "D05_NTH45.jpg ==> 3 NTH\n",
            "D07_HDH30.jpg ==> 1 HDH\n",
            "D09_NTH30.jpg ==> 3 NTH\n",
            "D17_NTH08.jpg ==> 3 NTH\n",
            "D08_Hyoam09.jpg ==> 2 Hyoam\n",
            "D13_ANH45.jpg ==> 0 ANH\n",
            "D12_HDH10.jpg ==> 1 HDH\n",
            "D09_Hyoam31.JPG ==> 2 Hyoam\n",
            "D03_OH13.jpg ==> 4 OH\n",
            "D09_HDH31.JPG ==> 0 ANH\n",
            "D06_OH41.jpg ==> 4 OH\n",
            "D07_ANH22.jpg ==> 0 ANH\n",
            "D18_Hyoam38.JPG ==> 2 Hyoam\n",
            "D18_ANH48.jpg ==> 0 ANH\n",
            "D11_NTH01.jpeg ==> 3 NTH\n",
            "D11_NTH30.jpeg ==> 3 NTH\n",
            "D12_OH21.jpg ==> 4 OH\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoIs2AwVoZ8w"
      },
      "source": [
        "the end!\n",
        "----"
      ]
    }
  ]
}
